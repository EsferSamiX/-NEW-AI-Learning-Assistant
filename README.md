# ğŸ§‘â€ğŸ’» AI Learning Assistant

An intelligent multi-module learning assistant built using **Streamlit + LLMs**, designed to support:

- ğŸ“š Educational Q&A (RAG-based)
- ğŸ“ AI Essay Writing
- ğŸ“„ PDF Summarization
- ğŸ§ª Question Generation
- ğŸ§  Exam Answer Evaluation
- ğŸ“† Adaptive Exam Study Planning

---

## ğŸš€ Features

### âœ… Educational Chatbot
- Retrieval-Augmented Generation (RAG)
- PDF-grounded answers only
- Page-level context referencing
- Conversation memory support

---

### âœ… AI Essay Writer
- Academic structure enforcement
- Automatic topic validation
- Optional outline support
- Plagiarism-safe generation
- Adjustable tone and length

---

### âœ… Text & PDF Summarization
- Short summary mode
- Bullet-point mode
- Chunk-based summarization
- Large-PDF support
- Token-safe processing

---

### âœ… Question Generator
- Easy / Medium / Hard difficulty levels
- Context-grounded questions only
- No hallucinated facts
- Supports technical and non-technical domains

---

### âœ… Answer Evaluation System
- Rubric-based academic grading
- Single-question evaluation
- Multi-question exam evaluation
- Strict reference-only marking

---

### âœ… Intelligent Exam Study Planner
- Difficulty-aware planning
- Minute-level scheduling
- 30-minute focus blocks
- Adaptive overload handling
- Automatic revision cycles
- Subtopic expansion using LLMs
---
Embedding Model : all-MiniLM-L6-v2
Deployment : Streamlit Cloud
LLM Model Used : Llama 3.3 70B versatile
---

## ğŸ—ï¸ Architecture Overview

UI (Streamlit)
â†“
Service Layer
â†“
Prompt Templates
â†“
LLM Client (Groq)
â†“
Vector Store (FAISS)

## ğŸ§© Folder Structure

ai-learning-assistant/
â”‚
â”œâ”€â”€ services/ # Core intelligence modules
â”‚â”œâ”€â”€ ai_essay_writer/
â”‚â”œâ”€â”€ ai_text_summarization/
â”‚â”œâ”€â”€ educational_chatbot/
â”‚â”œâ”€â”€ exam_study_planner/
â”‚â”œâ”€â”€ evaluation/
â”‚â”œâ”€â”€ question_generation/
â”‚â”œâ”€â”€ rag/
â”‚â””â”€â”€ core/
â”‚
â”œâ”€â”€ utils/
â”‚â”œâ”€â”€ prompt_templates.py # â­ All LLM prompts
â”‚â”œâ”€â”€ constants.py
â”‚â””â”€â”€ text_utils.py
â”‚
â”œâ”€â”€ UI/ # Streamlit UI components
â”‚
â”œâ”€â”€ .streamlit/
â”‚â”œâ”€â”€ config.toml
â”‚â”œâ”€â”€ secrets.toml # ignored
â”‚â””â”€â”€ secrets_example.toml
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore



## ğŸ” Environment Setup

### 1ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt

2ï¸âƒ£ Configure API key

Create:
.streamlit/secrets.toml
GROQ_API_KEY="your_api_key_here"


3ï¸âƒ£ Run application

streamlit run app.py
ğŸ§  LLM Design Philosophy

All prompts are centralized

No prompt logic inside services

Strict reference grounding

No hallucinated citations

Educational safety first

ğŸ§ª Supported Models

Groq LLM API

Easily extensible to:

OpenAI

Claude

Mistral

Local LLMs here used Llama 3.3 70B versatile

ğŸ‘¨â€ğŸ’» Author

Md Esfer Abdus Sami
2026
